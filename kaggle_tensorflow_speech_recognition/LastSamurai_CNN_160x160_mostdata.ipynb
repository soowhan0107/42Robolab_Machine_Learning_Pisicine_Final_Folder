{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "#Scientific Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "# Visualization Library\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 classes from the list : \n",
    "yes, no, up, down, left, right, on, off, stop, go\n",
    "\n",
    "2 classes below :\n",
    "1. Silence sliced up in 400 pictures (1 second per picture)\n",
    "2. everything else to unknown\n",
    "\n",
    "Take 1500 pictures from each class above - 15000 total\n",
    "and from the rest of 20 classes, take 500 pictures from each - 10000 pictures for unknown\n",
    "\n",
    "Possible Data Augmentation on 6 pictures for silence = 400\n",
    "\n",
    "-> for now, total of 15000 + 10000 + 400 = 25400 pictures.\n",
    "Everything in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = os.listdir('../input/audio/cat')\n",
    "down = os.listdir('../input/audio/down')\n",
    "four = os.listdir('../input/audio/four')\n",
    "house = os.listdir('../input/audio/house')\n",
    "nine = os.listdir('../input/audio/nine')\n",
    "on = os.listdir('../input/audio/on')\n",
    "seven = os.listdir('../input/audio/seven')\n",
    "stop = os.listdir('../input/audio/stop')\n",
    "two = os.listdir('../input/audio/two')\n",
    "yes = os.listdir('../input/audio/yes')\n",
    "bed = os.listdir('../input/audio/bed')\n",
    "eight = os.listdir('../input/audio/eight')\n",
    "go = os.listdir('../input/audio/go')\n",
    "left = os.listdir('../input/audio/left')\n",
    "no = os.listdir('../input/audio/no')\n",
    "one = os.listdir('../input/audio/one')\n",
    "sheila = os.listdir('../input/audio/sheila')\n",
    "three = os.listdir('../input/audio/three')\n",
    "up = os.listdir('../input/audio/up')\n",
    "zero = os.listdir('../input/audio/zero')\n",
    "bird = os.listdir('../input/audio/bird')\n",
    "dog = os.listdir('../input/audio/dog')\n",
    "five = os.listdir('../input/audio/five')\n",
    "happy = os.listdir('../input/audio/happy')\n",
    "marvin = os.listdir('../input/audio/marvin')\n",
    "off = os.listdir('../input/audio/off')\n",
    "right = os.listdir('../input/audio/right')\n",
    "six = os.listdir('../input/audio/six')\n",
    "tree = os.listdir('../input/audio/tree')\n",
    "wow = os.listdir('../input/audio/wow')\n",
    "silence = os.listdir('../input/audio/silence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(yes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by doing ls -R | wc -l, found out there are total of 64823 spectrogram. We will put in 100 from each first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.empty((100,129,256), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=0\n",
    "#image_name_list = sheila\n",
    "#for image_name in image_name_list[:100]:\n",
    "#    imageA = plt.imread('../input/audio/sheila/' + image_name)\n",
    "#    data[index] = imageA\n",
    "#    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "a=Image.open('../input/audio/yes/' + yes[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread('../input/audio/yes/' + yes[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imread('../input/audio/yes/' + yes[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imread('../input/audio/yes/' + yes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_list = yes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle images\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "shuffle(cat)\n",
    "shuffle(down)\n",
    "shuffle(four)\n",
    "shuffle(house)\n",
    "shuffle(nine)\n",
    "shuffle(on)\n",
    "shuffle(seven)\n",
    "shuffle(stop)\n",
    "shuffle(two)\n",
    "shuffle(yes)\n",
    "shuffle(bed)\n",
    "shuffle(eight)\n",
    "shuffle(go)\n",
    "shuffle(left)\n",
    "shuffle(no)\n",
    "shuffle(one)\n",
    "shuffle(sheila)\n",
    "shuffle(three)\n",
    "shuffle(up)\n",
    "shuffle(zero)\n",
    "shuffle(bird)\n",
    "shuffle(dog)\n",
    "shuffle(five)\n",
    "shuffle(happy)\n",
    "shuffle(marvin)\n",
    "shuffle(off)\n",
    "shuffle(right)\n",
    "shuffle(six)\n",
    "shuffle(tree)\n",
    "shuffle(wow)\n",
    "shuffle(silence)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Yes Spectrogram Images to Pixels\n",
    "\n",
    "data = np.empty((43400,160,160,3), dtype=np.float32)\n",
    "\n",
    "# top 10\n",
    "\n",
    "index = 0\n",
    "image_name_list = yes\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/yes/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = no\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/no/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "        \n",
    "image_name_list = up\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/up/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = down\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/down/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = left\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/left/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = right\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/right/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = on\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/on/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = off\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/off/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = stop\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/stop/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = go\n",
    "for image_name in image_name_list[:2300]:\n",
    "    imageA = plt.imread('../input/audio/go/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "# Top 10 done\n",
    "\n",
    "# Silence 100 pictures  \n",
    "image_name_list = silence\n",
    "for image_name in image_name_list[:400]:\n",
    "    imageA = plt.imread('../input/audio/silence/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1    \n",
    "\n",
    "# Unknown : 100 pictures from the rest\n",
    "    \n",
    "image_name_list = cat\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/cat/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "     \n",
    "image_name_list = four\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/four/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = house\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/house/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = nine\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/nine/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = seven\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/seven/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = two\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/two/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "\n",
    "image_name_list = bed\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/bed/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = eight\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/eight/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = one\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/one/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = sheila\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/sheila/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = three\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/three/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = zero\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/zero/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = bird\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/bird/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = dog\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/dog/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = five\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/five/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = happy\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/happy/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = marvin\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/marvin/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1 \n",
    "    \n",
    "image_name_list = six\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/six/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = tree\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/tree/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1\n",
    "    \n",
    "image_name_list = wow\n",
    "for image_name in image_name_list[:1000]:\n",
    "    imageA = plt.imread('../input/audio/wow/' + image_name)\n",
    "    data[index] = imageA\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25400 data sets with 12 classes with last class with 20 different in it\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if the end is not empty meaning that 3000 has all been transferred\n",
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show one image\n",
    "plt.imshow(data[-1])\n",
    "print(data[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min of pixel : \" + str(data.min()))\n",
    "print(\"max of pixel : \" + str(data.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#concatenate all the flattened spectrograms in order\n",
    "fl_data = np.empty((4800,2500), dtype=np.float32)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    flat = data[i].flatten()\n",
    "    fl_data[i] = flat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# check if transferred all\n",
    "print(\"size : \" + str(fl_data.shape))\n",
    "print(fl_data[-1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(30):\n",
    "#    print(i % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique\n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        print (x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "label = np.zeros((2300,), dtype=int)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    label = np.concatenate((label, np.repeat(i, 2300)))\n",
    "    \n",
    "label = np.concatenate((label, np.repeat(10, 400)))\n",
    "label = np.concatenate((label, np.repeat(11, 20000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(label, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape)\n",
    "print(type(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = label.reshape((4800,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(np.float64(label[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fl_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#one hot encode the lable\n",
    "b = np.zeros((label.size, label.max()+1))\n",
    "b[np.arange(label.size), label] = 1\n",
    "#labels = b\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check on prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(fl_data.shape)\n",
    "print(labels.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, label, test_size = 0.2)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5,6,7,8,9]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Helper f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={'x':x_train},\n",
    "      y=y_train,\n",
    "      batch_size=10,\n",
    "      num_epochs=2,\n",
    "      shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x':x_val},\n",
    "    y=y_val,\n",
    "    shuffle=False,\n",
    "    num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_function(features, labels, mode):\n",
    "  \n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 160, 160, 3])\n",
    "\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=32,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=64,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=128,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv6 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=128,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv6, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv7 = tf.layers.conv2d(\n",
    "        inputs=pool5,\n",
    "        filters=256,\n",
    "        kernel_size=[2, 2],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool6 = tf.layers.max_pooling2d(inputs=conv7, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    flat = tf.layers.flatten(pool6)\n",
    "    dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=dropout, units=12)\n",
    "    \n",
    "    predictions = {\n",
    "                \"classes\": tf.argmax(input=logits, axis=1),\n",
    "                \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions['classes'], name='acc_op')\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        tf.identity(accuracy[1], name='train_acc')\n",
    "        tf.summary.scalar('train_acc', accuracy[1])\n",
    "        eval_metric_ops = {'train_acc':accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    tf.identity(accuracy[1], name='val_accuracy')\n",
    "    tf.summary.scalar('val_accuracy', accuracy[1])\n",
    "    eval_metric_ops = {'val_accuracy':accuracy}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "                mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = './6_speech_rec_model'\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_function, model_dir=OUTDIR)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(estimator, epochs=100):\n",
    "    for i in range(epochs):\n",
    "        file_writer = tf.summary.FileWriter(OUTDIR)\n",
    "        estimator.train(input_fn=train_input_fn, steps=100)\n",
    "        file_writer = tf.summary.FileWriter(OUTDIR)\n",
    "        estimator.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "train_and_evaluate(cnn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  test_pict_path = '../input/test/test_160/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_function,\n",
    "    model_dir=\"./6_speech_rec_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imread('../input/test/test_160/clip_000044442.png').shape==(160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a test_data\n",
    "\n",
    "#predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#    x={'x':test_images},\n",
    "#    shuffle=False,\n",
    "#    num_epochs=2)\n",
    "\n",
    "#generator = cnn_classifier.predict(input_fn=predict_input_fn)\n",
    "\n",
    "#preds = []\n",
    "#b = []\n",
    "#for i in range(len(test_train)):\n",
    "#    a = next(generator)\n",
    "#    preds.append(a['classes'])\n",
    "#    b.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-divide into 10,000 test files to prevent tensor 2MB error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [y for y in os.listdir(test_pict_path) if '.png' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "corrupt = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[:10000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "        corrupt = corrupt+1\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "\n",
    "print(corrupt)\n",
    "\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x':test_images},\n",
    "    shuffle=False,\n",
    "    num_epochs=2)\n",
    "\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'a' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[10000:20000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'b' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[20000:30000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'c' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[30000:40000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'd' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[40000:50000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'e' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[50000:60000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'f' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[60000:70000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'g' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[70000:80000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'h' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[80000:90000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'i' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[90000:100000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'j' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[100000:110000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'k' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[110000:120000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'l' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[120000:130000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'm' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[130000:140000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'n' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[140000:150000]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'o' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[150000:]:\n",
    "    if (plt.imread(test_pict_path + file).shape == (160,160,3)):\n",
    "        test_images.append(plt.imread(test_pict_path + file))\n",
    "    else : \n",
    "        test_images.append(np.empty((160,160,3), dtype=np.float32))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "#test_images /= 255\n",
    "generator = classifier.predict(input_fn=predict_input_fn)\n",
    "preds=[]\n",
    "for i in range(len(test_images)):\n",
    "    a = next(generator)\n",
    "    preds.append(a['classes'])\n",
    "    \n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': preds})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('speech_' + 'p' + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'yes':0, 'no':1, 'up':2, 'down':3, 'left':4, 'right':5, 'on':6, 'off':7, \n",
    "              'stop':8, 'go':9, 'silence':10, 'unknown':11}\n",
    "\n",
    "reverse_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clip_25f96ade6.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clip_ac8fa1682.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip_cdadf318a.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip_7419f0d7e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clip_9e83292d5.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip_00f803721.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clip_aafb5a6d9.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip_0dee755a2.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clip_8070bb404.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clip_b3bef71f6.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clip_b94577f1e.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clip_4fd22b958.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clip_b3a950c47.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clip_c87b8ff71.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clip_a0039589b.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>clip_c7c4eaf1d.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clip_f6ff9e9b5.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clip_bfc01d316.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>clip_6984491f2.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clip_e51432c10.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clip_fe6ce335c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clip_3e0ed2f0a.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clip_c9f89457a.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clip_cc3cc2827.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clip_7cc8f3c63.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>clip_3070880b8.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>clip_6f112fd1e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>clip_fb1febbcd.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>clip_f8de61a7d.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clip_95442c1ad.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>clip_a409e7c59.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>clip_17a284d62.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>clip_ccc2cf3a0.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>clip_a022d6b0f.wav</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>clip_e80799edd.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>clip_590b569d6.wav</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>clip_f307872c0.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>clip_97bddae19.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>clip_9a3d8e307.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>clip_192c4c8b7.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>clip_aa5f97a5e.wav</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>clip_4d132f74e.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>clip_f213e6669.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>clip_cceddadaf.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>clip_e4409418c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>clip_3405ed2d1.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>clip_4b2d5d22f.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>clip_f7d8f27d3.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>clip_08e2f8e78.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>clip_1374683d1.wav</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>clip_135bc0720.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>clip_b903ccfbb.wav</td>\n",
       "      <td>silence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>clip_d63120591.wav</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>clip_c0f642e3c.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>clip_82890a52e.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>clip_fd9ac86a1.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>clip_61a6cc3a0.wav</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>clip_701cc7171.wav</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>clip_38d480e69.wav</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8537</th>\n",
       "      <td>clip_7843dfbdb.wav</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158538 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname    label\n",
       "0     clip_25f96ade6.wav     stop\n",
       "1     clip_ac8fa1682.wav  unknown\n",
       "2     clip_cdadf318a.wav     left\n",
       "3     clip_7419f0d7e.wav  unknown\n",
       "4     clip_9e83292d5.wav  unknown\n",
       "5     clip_00f803721.wav  unknown\n",
       "6     clip_aafb5a6d9.wav       no\n",
       "7     clip_0dee755a2.wav      off\n",
       "8     clip_8070bb404.wav  unknown\n",
       "9     clip_b3bef71f6.wav       up\n",
       "10    clip_b94577f1e.wav      yes\n",
       "11    clip_4fd22b958.wav  unknown\n",
       "12    clip_b3a950c47.wav  unknown\n",
       "13    clip_c87b8ff71.wav  unknown\n",
       "14    clip_a0039589b.wav       up\n",
       "15    clip_c7c4eaf1d.wav  unknown\n",
       "16    clip_f6ff9e9b5.wav  unknown\n",
       "17    clip_bfc01d316.wav  unknown\n",
       "18    clip_6984491f2.wav      off\n",
       "19    clip_e51432c10.wav  unknown\n",
       "20    clip_fe6ce335c.wav  unknown\n",
       "21    clip_3e0ed2f0a.wav      yes\n",
       "22    clip_c9f89457a.wav     left\n",
       "23    clip_cc3cc2827.wav      off\n",
       "24    clip_7cc8f3c63.wav  unknown\n",
       "25    clip_3070880b8.wav  unknown\n",
       "26    clip_6f112fd1e.wav  unknown\n",
       "27    clip_fb1febbcd.wav  unknown\n",
       "28    clip_f8de61a7d.wav  unknown\n",
       "29    clip_95442c1ad.wav     stop\n",
       "...                  ...      ...\n",
       "8508  clip_a409e7c59.wav  unknown\n",
       "8509  clip_17a284d62.wav  unknown\n",
       "8510  clip_ccc2cf3a0.wav  unknown\n",
       "8511  clip_a022d6b0f.wav       no\n",
       "8512  clip_e80799edd.wav  silence\n",
       "8513  clip_590b569d6.wav    right\n",
       "8514  clip_f307872c0.wav      off\n",
       "8515  clip_97bddae19.wav     left\n",
       "8516  clip_9a3d8e307.wav      yes\n",
       "8517  clip_192c4c8b7.wav  unknown\n",
       "8518  clip_aa5f97a5e.wav      yes\n",
       "8519  clip_4d132f74e.wav     down\n",
       "8520  clip_f213e6669.wav  unknown\n",
       "8521  clip_cceddadaf.wav     left\n",
       "8522  clip_e4409418c.wav  unknown\n",
       "8523  clip_3405ed2d1.wav  unknown\n",
       "8524  clip_4b2d5d22f.wav  unknown\n",
       "8525  clip_f7d8f27d3.wav  unknown\n",
       "8526  clip_08e2f8e78.wav  unknown\n",
       "8527  clip_1374683d1.wav      off\n",
       "8528  clip_135bc0720.wav  silence\n",
       "8529  clip_b903ccfbb.wav  silence\n",
       "8530  clip_d63120591.wav     left\n",
       "8531  clip_c0f642e3c.wav  unknown\n",
       "8532  clip_82890a52e.wav  unknown\n",
       "8533  clip_fd9ac86a1.wav  unknown\n",
       "8534  clip_61a6cc3a0.wav  unknown\n",
       "8535  clip_701cc7171.wav     down\n",
       "8536  clip_38d480e69.wav       up\n",
       "8537  clip_7843dfbdb.wav     stop\n",
       "\n",
       "[158538 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = pd.read_csv(\"./speech_\" + 'a' + \".csv\",sep=\",\")\n",
    "d1 = pd.read_csv(\"./speech_\" + 'b' + \".csv\",sep=\",\")\n",
    "d2 = pd.read_csv(\"./speech_\" + 'c' + \".csv\",sep=\",\")\n",
    "d3 = pd.read_csv(\"./speech_\" + 'd' + \".csv\",sep=\",\")\n",
    "d4 = pd.read_csv(\"./speech_\" + 'e' + \".csv\",sep=\",\")\n",
    "d5 = pd.read_csv(\"./speech_\" + 'f' + \".csv\",sep=\",\")\n",
    "d6 = pd.read_csv(\"./speech_\" + 'g' + \".csv\",sep=\",\")\n",
    "d7 = pd.read_csv(\"./speech_\" + 'h' + \".csv\",sep=\",\")\n",
    "d8 = pd.read_csv(\"./speech_\" + 'i' + \".csv\",sep=\",\")\n",
    "d9 = pd.read_csv(\"./speech_\" + 'j' + \".csv\",sep=\",\")\n",
    "d10 = pd.read_csv(\"./speech_\" + 'k' + \".csv\",sep=\",\")\n",
    "d11 = pd.read_csv(\"./speech_\" + 'l' + \".csv\",sep=\",\")\n",
    "d12 = pd.read_csv(\"./speech_\" + 'm' + \".csv\",sep=\",\")\n",
    "d13 = pd.read_csv(\"./speech_\" + 'n' + \".csv\",sep=\",\")\n",
    "d14 = pd.read_csv(\"./speech_\" + 'o' + \".csv\",sep=\",\")\n",
    "d15 = pd.read_csv(\"./speech_\" + 'p' + \".csv\",sep=\",\")\n",
    "\n",
    "df = [d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15]\n",
    "dx = pd.concat(df)\n",
    "\n",
    "dx = dx.replace({\"label\": reverse_dict})\n",
    "\n",
    "dx.to_csv('submission_v11.csv', index=False)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>down</th>\n",
       "      <td>5520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>2697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>5736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>6879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>6805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>5339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>4465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silence</th>\n",
       "      <td>5736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>6750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>97495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>6121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>4995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fname  label\n",
       "label                \n",
       "down      5520      1\n",
       "go        2697      1\n",
       "left      5736      1\n",
       "no        6879      1\n",
       "off       6805      1\n",
       "on        5339      1\n",
       "right     4465      1\n",
       "silence   5736      1\n",
       "stop      6750      1\n",
       "unknown  97495      1\n",
       "up        6121      1\n",
       "yes       4995      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.groupby('label').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
