{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"./Data/train.csv\")\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mnist.drop(\"label\", axis=1)\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pixel values\n",
    "x_data = x_data / 255\n",
    "x_data.iloc[:1,:].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = mnist[\"label\"]\n",
    "y_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = pd.get_dummies(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(x_data.values)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_data[:37000]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = x_data[37000:]\n",
    "x_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_labels[:37000].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_labels[37000:].values\n",
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization function\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return (tf.Variable(init_random_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias initialization function\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d convolution function which is already performed by tf\n",
    "def conv2d(x, W):\n",
    "    # x => input tensor ==> [batch, H, W, Channels]\n",
    "    # W => kernel => [filter height, filter width, # of channels in, # channels out]\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding=\"SAME\")\n",
    "# padding with SAME adds zeros to the end\n",
    "# Strides is how you want to move in the whole thing [batch, height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling function in this case max pooling which gets the max value and is a 2x2 kernel\n",
    "def max_pool_2by2(x):\n",
    "    # x=> input => [batch, h, w, c]\n",
    "    return (tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\"))\n",
    "# Ksize = size of the window which makces the pooling [batch, h, w, c] => here 1 is like pasing all 2 is reducing\n",
    "    # We only want to reduce the height and width of the image, that is why we use \n",
    "    # [1 in batch, 2 in height, 2 in width, 1 in channel]\n",
    "#  Stride here is [1, 2, 2, 1] because we want to shorten the image so we jump 2 by 2 pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer function\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]]) \n",
    "    # we take the third one because that is the number of channels we are using\n",
    "    # is not really intuitive but the channels is like the number of features\n",
    "    # first is going to be 1 then more\n",
    "    return (tf.nn.relu(conv2d(input_x, W)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal layaer (fully connected layer)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1]) \n",
    "    # we use the index one beacause 0 is the batch size and 1 is the number of nodes\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return (tf.matmul(input_layer, W)+b)\n",
    "# simple weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image layer => change the image to a 28 by 28 grid again\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# the -1 is a special value in the reshape function which means that the value is going to be computed so that \n",
    "# everythinh else in the array remains constant\n",
    "#If one component of shape is the special value -1, the size of that dimension is computed so that \n",
    "# the total size remains constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer\n",
    "convo_1 = convolutional_layer(x_image, shape=[5,5,1,32]) \n",
    "#we are using a 5x5 filter with 1 channel in and 32 features out\n",
    "# 32 feaures out means that we are going to apply the filter to the whole image 32 times\n",
    "# First pooling layer\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer 2\n",
    "convo_2 = convolutional_layer(convo_1_pooling, shape=[5,5,32,64])\n",
    "# 32 because we are getting that many features from the past convo and 64 is the number we want to get out of it\n",
    "# remember we get those features by the matrix multiplication\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we flatten the result\n",
    "# it is important to notice that we have a 7by7 image right now because the convolution has padding,\n",
    "# which makes the image to just go throuhg the layer withou loosing its size\n",
    "# So the only thing changing the size are the pooling layer which diivide the width and height by 2 and then again by 2\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1, 7*7*64])\n",
    "# 7*7 because of the width and height and 64 because of the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we put the normal full layer\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))\n",
    "# 1024 is just the number of nodes we want on the next layer, which is just based in the model we are creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization function which is dropout\n",
    "hold_prob = tf.placeholder(tf.float32) # just keeps our probability of a node staying\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "# tf function only need the probability and the layer you want to make dropout to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final layer to reduce to number of results\n",
    "y_pred = normal_full_layer(full_one_dropout, 10)\n",
    "# we only want ten results one for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error funcitons\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable initializer\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savers\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summaries for tensorboard\n",
    "merged_summary_op = tf.summary.merge_all() # this will get all the summaries from the graph and join them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # to use tensorboard you need to have a file writer to keep the logs\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorboard/train\", graph=tf.get_default_graph())\n",
    "    validation_writer = tf.summary.FileWriter(\"./tensorboard/validation\", graph=tf.get_default_graph())\n",
    "    \n",
    "    for i in range(steps + 1):\n",
    "        \n",
    "        rand_ind = np.random.randint(len(x_train), size=batch_size)\n",
    "        # Here we add hold_prob to our feed dictionary because it is a placeholder\n",
    "        feed = {x:x_train[rand_ind], y_true:y_train[rand_ind], hold_prob:0.5}\n",
    "        sess.run(train, feed_dict=feed)\n",
    "        \n",
    "        \n",
    "        # When runnining you need to append logs for tensorboard\n",
    "        if i%50 == 0:\n",
    "            summary = sess.run(merged_summary_op,\n",
    "                                      {x:x_train[rand_ind], y_true:y_train[rand_ind], hold_prob:1.0})\n",
    "            train_writer.add_summary(summary, i)\n",
    "            train_writer.flush()\n",
    "            summary = sess.run(merged_summary_op,\n",
    "                                      {x:x_validation, y_true:y_validation, hold_prob:1.0})\n",
    "            validation_writer.add_summary(summary, i)\n",
    "            validation_writer.flush()\n",
    "            print(\"checkpoints #{}\".format(i))\n",
    "    \n",
    "    saver.save(sess, \"cnn_model/cnn.ckpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./Data/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[0:1,:].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[0:1,:].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.values\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"cnn_model/cnn.ckpy\")\n",
    "    \n",
    "    prediction = y_pred\n",
    "    predictions = sess.run(prediction, feed_dict={x:test_data, hold_prob:1.0})\n",
    "    result = []\n",
    "    decode = tf.argmax(predictions, axis=1)\n",
    "    result = sess.run(decode)\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result, columns=[\"Label\"], dtype=int)\n",
    "result_df.index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.index.name = \"ImageId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./result_for_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tensorboard on terminal home directory\n",
    "# tensorboard --logdir=./tensorboard "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
